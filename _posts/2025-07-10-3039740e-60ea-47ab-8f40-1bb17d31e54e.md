---
title: "AI 활용, 감시, 그리고 투명성: 오늘의 세 가지 풍경"
date: 2025-07-10 20:00:35 +0900
categories: [뉴스, IT]
tags: []
---

## AI의 또다른 얼굴: 치트 툴일까, 혁신적 생산성 도구일까

인공지능(AI)이 일상에서 차지하는 역할이 커지면서, 그 활용 방식과 사회적 파장에 대한 논의도 더 깊어진다. 최근 주목받은 스타트업 Cluely는 '온라인 대화 분석'을 내세우며, 브라우저 안에서 동작하는 AI로 빠르게 유명세를 탔다. 한때 "치트(cheat) 툴"로 마케팅하며 논란을 자초했던 이 회사는, 공동창업자 Roy Lee가 구직 과정에서 실제로 이 도구를 이용해 코딩 시험에서 부정행위를 했다고 자랑한 사실이 알려져 콜롬비아대에서 정학당하기까지 했다.

이런 이슈에 반발해 'Truely'라는 감지 툴이 개발됐다. 이 제품은 온라인 인터뷰 등에서 Cluely를 비롯한 비인가 앱 사용을 탐지한다고 주장한다. Cluely 측은 오히려 "감지 당하든 상관없다"는 입장이었다. 실제로 Cluely의 '은닉 기능'은 기업 이용자 대부분이 법적 이유로 꺼 놓는 옵션에 불과하며, 오히려 사용의 투명성을 강조하는 방향으로 마케팅 전략을 전환했다.

이 과정에서 Cluely가 얻었던 명성 상당수는 "분노(bait)" 마케팅에 기댄 것이었다. 사람들이 치트를 문제 삼고 관심을 모으는 사이, Cluely는 이미 자신의 브랜드를 각인시킨 셈이다. 하지만 회사 측의 진짜 목표는 치트 툴이 아니라, ChatGPT와 같은 범용 AI 어시스턴트 시장에서 우위를 노리는 데 있다. 연구와 개발 측면에서도 Cluely는 화면과 오디오 정보를 적극적으로 활용해, 기존 AI보다 강한 현장 적응성을 경쟁력으로 내세우는 모습이다.

여기에서 드는 의문 하나: AI의 본질적 기능과 사회적 신뢰, 이 둘 사이의 균형은 어떻게 잡을 수 있을까?

## 생산성 혁명과 일자리: AI 도입의 명과 암

기업에서의 AI 확산은 생산성, 비용 절감 등 실질적 효과로 연결되고 있다. Microsoft는 지난 해 콜센터 운영 분야에서 AI 기반 자동화 기술을 도입해 5억 달러 이상의 비용을 절감한 것으로 나타났다. 사내 발표에 따르면, 영업, 고객 서비스, SW 엔지니어링 등 다양한 영역에서 효율 향상이 확인됐다. 

하지만 이 같은 기술 혁신의 그림자는 분명히 존재한다. Microsoft는 2024년 한 해 동안만 세 차례에 걸쳐 약 1만5천 명의 직원을 감원했다. 전체 매출은 700억 달러, 순이익은 260억 달러에 달하지만, AI 도입으로 인한 효율화가 직접적 일자리 감소와 연결되는 양상이 엿보인다. 

더불어, 등장한 일각의 조언도 논란을 키웠다. 회사 내부 인재가 “해고의 충격이 크다면 AI 도구를 활용해 감정적 부담이나 업무를 관리하라”는 취지의 발언을 해, 과연 이 변화가 모두에게 공정한가라는 또 다른 질문을 던지게 했다. 

Microsoft는 앞으로도 AI 인프라 확충에 막대한 자금을 투입할 계획이다. 일각에서는 AI 인재와 연구 부문에는 초고액 연봉을 제시하는 반면, 기존의 중간관리자나 일반 직원에게는 더 적은 기회가 돌아가는 현실이 부각된다. 생산성 혁명이 전통적인 고용 구조와 어떻게 다른 영향을 미치는지, 사회적 합의가 절실해 보인다.

## AI 거버넌스: 기술 혁신과 투명성의 줄다리기

AI 기술에 대한 사회적 우려가 높아지면서, 제도권의 통제와 투명성 요구도 함께 커지는 중이다. 캘리포니아주에서는 선도적인 AI 기업들에게 안전·보안 규정 공개와 사고 보고 의무를 부과하는 내용을 담은 법안(SB 53)이 의회에 상정됐다. 이 법이 통과될 경우, OpenAI, Google, Anthropic, xAI와 같은 대형 AI 기업들은 시스템 안전에 관한 내부 절차를 의무적으로 공개해야 한다.

이 과정은 쉽지 않았다. 이전의 더 강경했던 법안(SB 1047)은 기업들의 거센 반발로 주지사 거부권에 막혔다. 새롭게 개정된 SB 53은 기술 생태계의 성장 동력을 해치지 않으면서 '투명성'을 최소 기준으로 삼았다. AI 기업이 사회에 미치는 잠재적 위험이 드러날 경우, 내부 고발자 보호 조치까지 포함해 책임의 최소한을 담보하도록 했다.

특히 Google, OpenAI 등 주요 업체들이 최근 일부 AI 모델의 안전보고서 공개를 유예하거나 생략한 사례가 거론되면서, 기술 회사의 자율에만 맡길 수 없다는 현실이 드러났다. 실제로, 구글의 Gemini 2.5 Pro나 OpenAI의 GPT-4.1 등이 출시 당시 정식 보고서를 내지 않아 논란이 됐다.

SB 53은 이전보다 한 발 물러서 있긴 하지만, 대규모 AI 개발자에게 일정 수준의 투명성을 강제하는 내용을 담고 있다. AI 사고가 대규모 인명·재산 피해로 번질 경우를 상정해, 위험 알림 보고 기준도 마련됐다. 동시에, 오픈소스와 스타트업에는 부담이 가지 않도록 일부 면제 조항도 추가됐다.

이미지 삽입:
![대형 모니터 앞에서 회의 중인 AI 관련 전문가들, 긴장감이 감도는 사무실의 저녁](assets/img/2025-07-10-3039740e-60ea-47ab-8f40-1bb17d31e54e/1752145285282.png)

## 세 갈래 AI 이슈, 교차점과 상호작용

세 관점의 공통점은 AI 기술의 확산이 규제, 사회 윤리, 경제 구조 등 다양한 차원에서 긴장 상태를 만든다는 데 있다. Cluely와 같은 신생 기술 기업이 치트와 혁신 사이에서 논란을 자초하면서, AI의 도입 과정과 활용 범위에 대한 사회적 감시가 강화됐다. Microsoft 사례에서는 AI가 업무 효율화를 통해 기록적 수익을 창출하면서도 대규모 구조조정과 맞물려 기존 노동시장에 직접적 충격을 주는 사례가 등장했다.

캘리포니아의 움직임은 AI를 그냥 두고 볼 수 없는 지점에 와 있음을 보여 준다. 기술 발전의 속도를 저해하지 않으면서도 사회적 신뢰, 투명성, 안전망을 함께 구축하는 것이 핵심 과제로 자리 잡았다. 이 같은 조치들이 단순히 미국 대기업들만의 문제가 아니라, 결국 글로벌 표준 논의까지 확장된다는 점에 주목할 필요가 있다.

## 남는 질문들

- 치트 방지와 투명성의 강화: 기술의 발전 속에서 '올바른 사용'이란 무엇이고, 그 경계는 누가 정하는가.
- 일자리와 재분배: AI가 일으키는 초고도 자동화와 생산성 증대는 과연 사회 전체의 이익으로 귀결될 수 있는가.
- 책임과 신뢰: AI로 인한 안전사고 또는 권한 남용에 대한 책임 소재, 그리고 소비자와 시민에게 돌아가는 신뢰 확보 방법은 무엇인가.

이 질문들은 명확한 해답을 주지 않지만, 지금 이 시점에서 AI 기술과 사회의 교차지점들이 던지는 실제 고민이라고 할 수 있다. 앞으로도 AI는 기능 향상, 생산성 증대, 사회적 책임이라는 세 가지 화두가 끊임없이 교차하며 진화할 전망이다. 각 분야의 행보와 논쟁이 일상에 미치는 영향을 지속적으로 관찰하는 것이 중요하다.